{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using nvcr.io/nvidia/tritonserver:24.01-py3 (a previous version of triton which has onnxruntime backend installed (cuDNN upgrade issue in the newer one))\n",
    "\n",
    "# # First check support for tensorrt for the onnx model\n",
    "# /opt/tensorrt/bin/trtexec --onnx=/workspace/model_repository/nomic-embed-vision/1/model.onnx --verbose\n",
    "# /opt/tensorrt/bin/trtexec --onnx=/workspace/model_repository/UAE-Large-V1/1/model.onnx --verbose\n",
    "\n",
    "# # from onnx nomic-embed-vision to tensortt plan file\n",
    "# /opt/tensorrt/bin/trtexec --onnx=/workspace/model_repository/nomic-embed-vision/1/model.onnx --saveEngine=/workspace/model_repository/nomic-embed-vision/1/model.plan --fp16 --memPoolSize=workspace:12000\n",
    "\n",
    "# # now do the same for the text embedding model\n",
    "# /opt/tensorrt/bin/trtexec --onnx=/workspace/model_repository/UAE-Large-V1/1/model.onnx --saveEngine=/workspace/model_repository/UAE-Large-V1/1/model.plan --fp16 --memPoolSize=workspace:12000\n",
    "\n",
    "# # Start Triton\n",
    "# # My folder is network stored, so all packages should be accesible\n",
    "\n",
    "# /opt/tritonserver/bin/tritonserver --model-repository=/workspace/model_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMD\n",
    "# /bin/bash -c \"gdown --folder https://drive.google.com/drive/folders/1E2D2ekxGa4uQ2mu9zrURKb3f8l85fFjS -O /workspace/model_repository && /opt/tritonserver/bin/tritonserver --model-repository=/workspace/model_repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "\n",
    "payload = [\"a black\", \"hi there\", \"a red ball\"]\n",
    "response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_text\", json=payload)\n",
    "\n",
    "response_json = response.json()\n",
    "result_array = np.array(response_json['result'])\n",
    "result_array.shape\n",
    "\n",
    "for item in result_array:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Runpod API Endpoint\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "FAISS_TEXT_INDEX_PATH = \"text-embeddings/faiss_index.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating embeddings and saving FAISS index...\n",
      "‚úÖ FAISS index contains 10200 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define Paths\n",
    "FAISS_TEXT_INDEX_PATH = \"text-embeddings/faiss_index.bin\"\n",
    "EMBEDDINGS_CSV_PATH = \"text-embeddings/embeddings.csv\"\n",
    "\n",
    "# Define Runpod API Endpoint\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "\n",
    "# Load CSV\n",
    "df_products = pd.read_csv(\"D:/My Works/Challenges/Sereact/Embeddings-pipeline/dataset/textual/complete/final_products.csv\")\n",
    "\n",
    "# Generate text inputs\n",
    "text_inputs = df_products.apply(\n",
    "    lambda row: f\"Title of Product: {row['title']}\\nProduct Image Description: {row['llava_generated_image_caption']}\\nProduct Category: {row['category_name']}\", \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text_inputs, batch_size=128):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_inputs), batch_size):\n",
    "        batch = text_inputs[i:i + batch_size]\n",
    "        response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_text\", json=batch)\n",
    "        response_json = response.json()\n",
    "        batch_embeddings = np.array(response_json['result'])  # Shape (batch_size, tokens, 1024)\n",
    "        batch_embeddings = np.mean(batch_embeddings, axis=1)  # Averaging tokens\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Check if FAISS index exists\n",
    "if os.path.exists(FAISS_TEXT_INDEX_PATH):\n",
    "    print(\"üîπ Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(FAISS_TEXT_INDEX_PATH)\n",
    "    embeddings = np.loadtxt(EMBEDDINGS_CSV_PATH, delimiter=\",\")  # Load saved embeddings\n",
    "else:\n",
    "    print(\"üîπ Generating embeddings and saving FAISS index...\")\n",
    "    embeddings = get_embeddings(text_inputs)\n",
    "\n",
    "    # Create FAISS Index\n",
    "    d = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Save FAISS index\n",
    "    faiss.write_index(index, FAISS_TEXT_INDEX_PATH)\n",
    "    np.savetxt(EMBEDDINGS_CSV_PATH, embeddings, delimiter=\",\")  # Save embeddings\n",
    "\n",
    "print(f\"‚úÖ FAISS index contains {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 5 Similar Products:\n",
      "\n",
      "                                                 title       category_name  \\\n",
      "244  for MacBook Pro 13 inch Case M2/M1 A2338 A2289...  Laptop Accessories   \n",
      "528  for MacBook Pro 14 Inch 2023 2022 2021 Case M2...  Laptop Accessories   \n",
      "636  IBENZER Compatible MacBook Pro 14 Inch Case 20...  Laptop Accessories   \n",
      "548  A1398 Macbook Pro Battery A1417 for Macbook pr...  Laptop Accessories   \n",
      "330  Compatible with MacBook Pro 13 inch Case M2 20...  Laptop Accessories   \n",
      "\n",
      "       distance  \n",
      "244  161.664963  \n",
      "528  162.194870  \n",
      "636  162.937637  \n",
      "548  163.861755  \n",
      "330  166.678452  \n"
     ]
    }
   ],
   "source": [
    "# Function to Search for Similar Products\n",
    "def find_similar(query_text, index, df_products, k=5):\n",
    "    response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_text\", json=[query_text])\n",
    "    query_embedding = np.array(response.json()['result'])\n",
    "    query_embedding = np.mean(query_embedding, axis=1)  # Average token embeddings\n",
    "\n",
    "    distances, indices = index.search(query_embedding, k)  # Search FAISS index\n",
    "\n",
    "    # Retrieve the top similar products\n",
    "    similar_products = df_products.iloc[indices[0]].copy()\n",
    "    similar_products['distance'] = distances[0]  # Attach similarity scores\n",
    "    \n",
    "    return similar_products\n",
    "\n",
    "# Example Query\n",
    "query_text = \"Macbook pro\"\n",
    "index = faiss.read_index(FAISS_TEXT_INDEX_PATH)\n",
    "df_products = pd.read_csv(\"D:/My Works/Challenges/Sereact/Embeddings-pipeline/dataset/textual/complete/final_products.csv\")\n",
    "top_results = find_similar(query_text, index, df_products)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nüîç Top 5 Similar Products:\\n\")\n",
    "print(top_results[['title', 'category_name', 'distance']])  # Show key details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image embeddings inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating image embeddings and saving FAISS index...\n",
      "‚úÖ FAISS index contains 10199 image vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# Define Paths for Image FAISS Index\n",
    "FAISS_INDEX_IMG_PATH = \"image_embeddings/faiss_index_images.bin\"\n",
    "IMAGE_EMBEDDINGS_CSV_PATH = \"image_embeddings/image_embeddings.csv\"\n",
    "\n",
    "# Define Runpod API Endpoint\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "\n",
    "# Load CSV\n",
    "df_products = pd.read_csv(\"D:/My Works/Challenges/Sereact/Embeddings-pipeline/dataset/textual/complete/final_products.csv\")\n",
    "\n",
    "# Extract Image URLs\n",
    "image_urls = df_products['imgUrl'].tolist()\n",
    "\n",
    "# Function to Download Images and Get Embeddings\n",
    "def get_image_embeddings(image_urls, batch_size=64):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(image_urls), batch_size):\n",
    "        batch_urls = image_urls[i:i + batch_size]\n",
    "        files = []\n",
    "\n",
    "        # Download images\n",
    "        for j, url in enumerate(batch_urls):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                image_bytes = BytesIO(response.content)\n",
    "                files.append((\"images\", (f\"image_{i+j}.jpg\", image_bytes, \"image/jpeg\")))\n",
    "\n",
    "        # Send request to API\n",
    "        response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_image\", files=files)\n",
    "        response_json = response.json()\n",
    "        batch_embeddings = np.array(response_json['image_embeddings'])  # (batch_size, 768)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)  # Combine all batches\n",
    "\n",
    "# Check if FAISS index for images exists\n",
    "if os.path.exists(FAISS_INDEX_IMG_PATH) and os.path.exists(IMAGE_EMBEDDINGS_CSV_PATH):\n",
    "    print(\"üîπ Loading existing FAISS index for images...\")\n",
    "    index_images = faiss.read_index(FAISS_INDEX_IMG_PATH)\n",
    "    image_embeddings = np.loadtxt(IMAGE_EMBEDDINGS_CSV_PATH, delimiter=\",\")\n",
    "else:\n",
    "    print(\"üîπ Generating image embeddings and saving FAISS index...\")\n",
    "    image_embeddings = get_image_embeddings(image_urls)\n",
    "\n",
    "    # Create FAISS Index for images\n",
    "    d_img = image_embeddings.shape[1]  # Should be 768 dimensions\n",
    "    index_images = faiss.IndexFlatL2(d_img)\n",
    "    index_images.add(image_embeddings)\n",
    "\n",
    "    # Save FAISS index\n",
    "    faiss.write_index(index_images, FAISS_INDEX_IMG_PATH)\n",
    "    np.savetxt(IMAGE_EMBEDDINGS_CSV_PATH, image_embeddings, delimiter=\",\")\n",
    "\n",
    "print(f\"‚úÖ FAISS index contains {index_images.ntotal} image vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 5 Similar Images:\n",
      "\n",
      "                                                 title  \\\n",
      "1    Griffin Elevator Stand for Laptops - Lift Your...   \n",
      "845  200Pcs Workout Stickers Gym Inspirational Stic...   \n",
      "39   Laptop Stand for Desk, Computer Stand Adjustab...   \n",
      "107  Laptop Stand ‚Äî 360¬∞ Swivel & Adjustable Laptop...   \n",
      "46   HUANUO Adjustable Laptop Stand with 360¬∞ Rotat...   \n",
      "\n",
      "                                                imgUrl      distance  \n",
      "1    https://m.media-amazon.com/images/I/710N2S69Nv...  1.390227e-07  \n",
      "845  https://m.media-amazon.com/images/I/91+XDAqMOi...  6.427319e-02  \n",
      "39   https://m.media-amazon.com/images/I/71F3v-25Wm...  8.010767e-02  \n",
      "107  https://m.media-amazon.com/images/I/61ysSArXif...  1.025770e-01  \n",
      "46   https://m.media-amazon.com/images/I/81dj+1uUqr...  1.031212e-01  \n"
     ]
    }
   ],
   "source": [
    "# Function to Find Similar Images by URL\n",
    "def find_similar_images(image_url, k=5):\n",
    "    # Download image\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(\"Failed to download image!\")\n",
    "\n",
    "    image_bytes = BytesIO(response.content)\n",
    "    files = [(\"images\", (\"query_image.jpg\", image_bytes, \"image/jpeg\"))]\n",
    "\n",
    "    # Get query image embedding\n",
    "    response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_image\", files=files)\n",
    "    query_embedding = np.array(response.json()['image_embeddings'])  # (1, 768)\n",
    "\n",
    "    # Search FAISS index\n",
    "    distances, indices = index_images.search(query_embedding, k)\n",
    "\n",
    "    # Retrieve top similar images\n",
    "    similar_images = df_products.iloc[indices[0]].copy()\n",
    "    similar_images['distance'] = distances[0]\n",
    "\n",
    "    return similar_images\n",
    "\n",
    "# Example Image Query\n",
    "query_image_url = \"https://m.media-amazon.com/images/I/710N2S69NvL._AC_UL320_.jpg\"\n",
    "top_image_results = find_similar_images(query_image_url)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nüîç Top 5 Similar Images:\\n\")\n",
    "print(top_image_results[['title', 'imgUrl', 'distance']])  # Show relevant details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Triton is ready!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "RUNPOD_API_ENDPOINT = \"https://lhr3tmm415zpim-5000.proxy.runpod.net/\"\n",
    "\n",
    "def wait_for_server():\n",
    "    for _ in range(10):  # Check for 10 attempts (adjust if needed)\n",
    "        try:\n",
    "            response = requests.get(f\"{RUNPOD_API_ENDPOINT}/health\")\n",
    "            if response.status_code == 200 and response.json().get(\"status\") == \"ok\":\n",
    "                print(\"‚úÖ Triton is ready!\")\n",
    "                return True\n",
    "        except requests.exceptions.RequestException:\n",
    "            pass\n",
    "        \n",
    "        print(\"‚è≥ Waiting for Triton server to be ready...\")\n",
    "        time.sleep(3)  # Wait 3 seconds before retrying\n",
    "    \n",
    "    print(\"‚ùå Triton server is not available after multiple attempts.\")\n",
    "    return False\n",
    "\n",
    "# # ‚úÖ Wait until Triton is ready before making requests\n",
    "# if wait_for_server():\n",
    "#     print(\"üöÄ Proceed with inference!\")\n",
    "# else:\n",
    "#     print(\"üö® Cannot proceed with inference. Server is unavailable.\")\n",
    "wait_for_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

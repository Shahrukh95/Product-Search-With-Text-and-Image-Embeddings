{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating embeddings and saving FAISS index...\n",
      "‚úÖ FAISS index contains 10200 vectors.\n"
     ]
    }
   ],
   "source": [
    "# GENERATE TEXT EMBEDDINGS IN BATCHES OF 128\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define Paths\n",
    "FAISS_TEXT_INDEX_PATH = \"Embeddings/text-embeddings/faiss_index.bin\"\n",
    "EMBEDDINGS_CSV_PATH = \"Embeddings/text-embeddings/embeddings.csv\"\n",
    "\n",
    "# Define Runpod API Endpoint\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "\n",
    "df_products = pd.read_csv(\"dataset/textual/complete/final_products.csv\")\n",
    "\n",
    "# Generate text inputs\n",
    "text_inputs = df_products.apply(\n",
    "    lambda row: f\"Title of Product: {row['title']}\\nProduct Image Description: {row['llava_generated_image_caption']}\\nProduct Category: {row['category_name']}\", \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Get Text Embeddings form NVIDIA Triton Inference Server\n",
    "def get_embeddings(text_inputs, batch_size=128):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_inputs), batch_size):\n",
    "        batch = text_inputs[i:i + batch_size]\n",
    "        response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_text\", json=batch)\n",
    "        response_json = response.json()\n",
    "        batch_embeddings = np.array(response_json['result'])  # Shape (batch_size, tokens, 1024)\n",
    "        batch_embeddings = np.mean(batch_embeddings, axis=1)  # Averaging tokens to get single vector per text\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Check if FAISS index exists\n",
    "if os.path.exists(FAISS_TEXT_INDEX_PATH):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(FAISS_TEXT_INDEX_PATH)\n",
    "    embeddings = np.loadtxt(EMBEDDINGS_CSV_PATH, delimiter=\",\")  # Load saved embeddings\n",
    "else:\n",
    "    print(\"Generating embeddings and saving FAISS index...\")\n",
    "    embeddings = get_embeddings(text_inputs)\n",
    "\n",
    "    # Create FAISS Index\n",
    "    d = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Save FAISS index\n",
    "    faiss.write_index(index, FAISS_TEXT_INDEX_PATH)\n",
    "    np.savetxt(EMBEDDINGS_CSV_PATH, embeddings, delimiter=\",\")  # Save embeddings\n",
    "\n",
    "print(f\"FAISS index contains {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 5 Similar Products:\n",
      "\n",
      "                                                 title       category_name  \\\n",
      "244  for MacBook Pro 13 inch Case M2/M1 A2338 A2289...  Laptop Accessories   \n",
      "528  for MacBook Pro 14 Inch 2023 2022 2021 Case M2...  Laptop Accessories   \n",
      "636  IBENZER Compatible MacBook Pro 14 Inch Case 20...  Laptop Accessories   \n",
      "548  A1398 Macbook Pro Battery A1417 for Macbook pr...  Laptop Accessories   \n",
      "330  Compatible with MacBook Pro 13 inch Case M2 20...  Laptop Accessories   \n",
      "\n",
      "       distance  \n",
      "244  161.664963  \n",
      "528  162.194870  \n",
      "636  162.937637  \n",
      "548  163.861755  \n",
      "330  166.678452  \n"
     ]
    }
   ],
   "source": [
    "# Function to find similar products using input embedding and FAISS index\n",
    "\n",
    "def find_similar(query_text, index, df_products, k=5):\n",
    "    response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_text\", json=[query_text])\n",
    "    query_embedding = np.array(response.json()['result'])\n",
    "    query_embedding = np.mean(query_embedding, axis=1)  # Average token embeddings for the single query text\n",
    "\n",
    "    distances, indices = index.search(query_embedding, k)  # Search FAISS index\n",
    "\n",
    "    # Retrieve the top similar products\n",
    "    similar_products = df_products.iloc[indices[0]].copy()\n",
    "    similar_products['distance'] = distances[0]  # Attach similarity scores\n",
    "    \n",
    "    return similar_products\n",
    "\n",
    "# Example Query\n",
    "query_text = \"Macbook pro\"\n",
    "index = faiss.read_index(FAISS_TEXT_INDEX_PATH)\n",
    "df_products = pd.read_csv(\"dataset/textual/complete/final_products.csv\")\n",
    "top_results = find_similar(query_text, index, df_products)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nüîç Top 5 Similar Products:\\n\")\n",
    "print(top_results[['title', 'category_name', 'distance']])  # Show key details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating image embeddings and saving FAISS index...\n",
      "‚úÖ FAISS index contains 10199 image vectors.\n"
     ]
    }
   ],
   "source": [
    "# # GENERATE IMAGE EMBEDDINGS IN BATCHES OF 64\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# Define Paths for Image FAISS Index\n",
    "FAISS_INDEX_IMG_PATH = \"Embeddings/image_embeddings/faiss_index_images.bin\"\n",
    "IMAGE_EMBEDDINGS_CSV_PATH = \"Embeddings/image_embeddings/image_embeddings.csv\"\n",
    "\n",
    "# Define Runpod API Endpoint\n",
    "RUNPOD_API_ENDPOINT = \"https://26oe7qh881svy7-5000.proxy.runpod.net/\"\n",
    "\n",
    "df_products = pd.read_csv(\"dataset/textual/complete/final_products.csv\")\n",
    "\n",
    "image_urls = df_products['imgUrl'].tolist()\n",
    "\n",
    "# Function to Download Images and Get Embeddings\n",
    "def get_image_embeddings(image_urls, batch_size=64):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(image_urls), batch_size):\n",
    "        batch_urls = image_urls[i:i + batch_size]\n",
    "        files = []\n",
    "\n",
    "        # Download images\n",
    "        for j, url in enumerate(batch_urls):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                image_bytes = BytesIO(response.content)\n",
    "                files.append((\"images\", (f\"image_{i+j}.jpg\", image_bytes, \"image/jpeg\")))\n",
    "\n",
    "        # Send request to NVIDIA Triton Inference Server\n",
    "        response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_image\", files=files)\n",
    "        response_json = response.json()\n",
    "        batch_embeddings = np.array(response_json['image_embeddings'])  # (batch_size, 768) for this model\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)  # Combine all batches\n",
    "\n",
    "if os.path.exists(FAISS_INDEX_IMG_PATH) and os.path.exists(IMAGE_EMBEDDINGS_CSV_PATH):\n",
    "    print(\"Loading existing FAISS index for images...\")\n",
    "    index_images = faiss.read_index(FAISS_INDEX_IMG_PATH)\n",
    "    image_embeddings = np.loadtxt(IMAGE_EMBEDDINGS_CSV_PATH, delimiter=\",\")\n",
    "else:\n",
    "    print(\"Generating image embeddings and saving FAISS index...\")\n",
    "    image_embeddings = get_image_embeddings(image_urls)\n",
    "\n",
    "    # Create FAISS Index for images\n",
    "    d_img = image_embeddings.shape[1]  # Should be 768 dimensions for this model\n",
    "    index_images = faiss.IndexFlatL2(d_img)\n",
    "    index_images.add(image_embeddings)\n",
    "\n",
    "    # Save FAISS index\n",
    "    faiss.write_index(index_images, FAISS_INDEX_IMG_PATH)\n",
    "    np.savetxt(IMAGE_EMBEDDINGS_CSV_PATH, image_embeddings, delimiter=\",\")\n",
    "\n",
    "print(f\"FAISS index contains {index_images.ntotal} image vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find similar products using image embeddings generated by a URL and FAISS index\n",
    "\n",
    "def find_similar_images(image_url, k=5):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(\"Failed to download image!\")\n",
    "\n",
    "    image_bytes = BytesIO(response.content)\n",
    "    files = [(\"images\", (\"query_image.jpg\", image_bytes, \"image/jpeg\"))]\n",
    "\n",
    "    # Get query image embedding\n",
    "    response = requests.post(f\"{RUNPOD_API_ENDPOINT}/infer_image\", files=files)\n",
    "    query_embedding = np.array(response.json()['image_embeddings'])  # (1, 768)\n",
    "\n",
    "    # Search FAISS index\n",
    "    distances, indices = index_images.search(query_embedding, k)\n",
    "\n",
    "    similar_images = df_products.iloc[indices[0]].copy()\n",
    "    similar_images['distance'] = distances[0]\n",
    "\n",
    "    return similar_images\n",
    "\n",
    "# Example Image Query\n",
    "query_image_url = \"https://m.media-amazon.com/images/I/710N2S69NvL._AC_UL320_.jpg\"\n",
    "top_image_results = find_similar_images(query_image_url)\n",
    "\n",
    "print(\"Top 5 Similar Images:\\n\")\n",
    "print(top_image_results[['title', 'imgUrl', 'distance']])  # Show relevant details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Triton is ready!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An optional function to wait for the Triton server to be ready before making requests\n",
    "import requests\n",
    "import time\n",
    "\n",
    "RUNPOD_API_ENDPOINT = \"https://lhr3tmm415zpim-5000.proxy.runpod.net/\"\n",
    "\n",
    "def wait_for_server():\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            response = requests.get(f\"{RUNPOD_API_ENDPOINT}/health\")\n",
    "            if response.status_code == 200 and response.json().get(\"status\") == \"ok\":\n",
    "                print(\"Triton is ready!\")\n",
    "                return True\n",
    "        except requests.exceptions.RequestException:\n",
    "            pass\n",
    "        \n",
    "        print(\"Waiting for Triton server to be ready...\")\n",
    "        time.sleep(3)\n",
    "    \n",
    "    print(\"Triton server is not available after multiple attempts.\")\n",
    "    return False\n",
    "\n",
    "wait_for_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

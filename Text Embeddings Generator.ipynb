{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56710e91-e99d-4d1c-8f73-c0b87656754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367ba7bc30614af68690ffbb4b51ee5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Model name\n",
    "model_name = \"Linq-AI-Research/Linq-Embed-Mistral\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee28347-f038-4373-913c-2ea03985338d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>imgUrl</th>\n",
       "      <th>productURL</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>category_id</th>\n",
       "      <th>isBestSeller</th>\n",
       "      <th>boughtInLastMonth</th>\n",
       "      <th>id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>llava_generated_image_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B08ZDQX51W</td>\n",
       "      <td>Original Replacement Dell 130W Laptop Charger ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61sADwl+YW...</td>\n",
       "      <td>https://www.amazon.com/dp/B08ZDQX51W</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24.98</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Laptop Accessories</td>\n",
       "      <td>A black power bank, which is a portable charge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01BPCTXHC</td>\n",
       "      <td>Griffin Elevator Stand for Laptops - Lift Your...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/710N2S69Nv...</td>\n",
       "      <td>https://www.amazon.com/dp/B01BPCTXHC</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Laptop Accessories</td>\n",
       "      <td>A laptop computer sitting on a stand or a dock...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title  \\\n",
       "0  B08ZDQX51W  Original Replacement Dell 130W Laptop Charger ...   \n",
       "1  B01BPCTXHC  Griffin Elevator Stand for Laptops - Lift Your...   \n",
       "\n",
       "                                              imgUrl  \\\n",
       "0  https://m.media-amazon.com/images/I/61sADwl+YW...   \n",
       "1  https://m.media-amazon.com/images/I/710N2S69Nv...   \n",
       "\n",
       "                             productURL  stars  reviews  price  category_id  \\\n",
       "0  https://www.amazon.com/dp/B08ZDQX51W    4.5        0  24.98           65   \n",
       "1  https://www.amazon.com/dp/B01BPCTXHC    4.6        0  35.00           65   \n",
       "\n",
       "   isBestSeller  boughtInLastMonth  id       category_name  \\\n",
       "0         False                  0  65  Laptop Accessories   \n",
       "1         False                  0  65  Laptop Accessories   \n",
       "\n",
       "                       llava_generated_image_caption  \n",
       "0  A black power bank, which is a portable charge...  \n",
       "1  A laptop computer sitting on a stand or a dock...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_products = pd.read_csv(\"final_products.csv\")\n",
    "df_products.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee387b9-5283-49d0-a76e-3f9825a1ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title of Product: Original Replacement Dell 130W Laptop Charger USB C Slim AC Power Adapter for Dell Xps 17,Precision 5550 5530 2in1,XPS 15 2in1 9575ï¼ŒDA130PM170 HA130PM170 0K00F5 K00F5 0M0H25 M0H25 T4V18\\nProduct Image Description: A black power bank, which is a portable charger used to charge electronic devices.\\nProduct Category: Laptop Accessories',\n",
       " 'Title of Product: Griffin Elevator Stand for Laptops - Lift Your Laptop to a Comfortable Viewing Height, Space Grey\\nProduct Image Description: A laptop computer sitting on a stand or a docking station.\\nProduct Category: Laptop Accessories']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array = df_products.apply(lambda row: f\"Title of Product: {row['title']}\\nProduct Image Description: {row['llava_generated_image_caption']}\\nProduct Category: {row['category_name']}\", axis=1).tolist()\n",
    "result_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67731c9-60fb-41e3-b1d0-d84d3684dcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1718056-e205-4d9c-a060-25a498f7ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10200, 4096)\n",
      "[[-0.00223  -0.01529  -0.01616  ...  0.01277  -0.03455  -0.00944 ]\n",
      " [ 0.005222 -0.002394  0.02354  ...  0.011246 -0.0284   -0.01431 ]\n",
      " [-0.00896   0.00813   0.01146  ...  0.003876 -0.02586  -0.006336]\n",
      " ...\n",
      " [-0.01182   0.0189    0.008095 ... -0.003273 -0.01124   0.001532]\n",
      " [-0.00619   0.004642  0.01692  ... -0.004555 -0.00444  -0.004665]\n",
      " [-0.01607   0.00909   0.012535 ... -0.00455  -0.00888   0.01744 ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def last_token_pool(last_hidden_states, attention_mask):\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def get_embeddings(texts, model, tokenizer, max_length=4096, batch_size=32):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "\n",
    "        batch_dict = tokenizer(batch_texts, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        batch_dict = {k: v.to(model.device) for k, v in batch_dict.items()}\n",
    "\n",
    "        # Get model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict)\n",
    "\n",
    "        # Extract last token embeddings\n",
    "        embeddings = last_token_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "\n",
    "        # Normalize embeddings\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        # Convert to numpy and store\n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "embeddings = get_embeddings(result_array, model, tokenizer, batch_size=batch_size)\n",
    "\n",
    "print(embeddings.shape)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f926200-f73a-459b-b62f-ea4d0fbe6be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c798fd5c-3c8a-47b7-b06c-0893d37fe920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6d295-3ee5-42a1-8ab1-5a59c0d80b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97ef377-f0f7-4e62-a7a3-a492ad6215bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad7d5aa-9786-4f69-a64c-884a51f33967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 10200\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert embeddings to float32\n",
    "embeddings_f32 = np.ascontiguousarray(embeddings.astype(np.float32))\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "embeddings_f32 = F.normalize(torch.tensor(embeddings_f32), p=2, dim=1).numpy()\n",
    "\n",
    "# Create FAISS index for Inner Product (Cosine Similarity)\n",
    "index = faiss.IndexFlatIP(embeddings_f32.shape[1])\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings_f32)\n",
    "\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f80adf-2070-43e8-a977-8e05ca7d9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"Text Vector Store/vector_store.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209eafb-2acd-438e-9229-0e70a049070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"Text Vector Store/vector_store.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e4d60-27ef-441d-b3c1-06889b112f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87ee7b-4b1d-4044-81e2-dd97909605d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43364e03-ea85-498b-8780-e24a9722d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar product indices: [[324 261 269]]\n",
      "Similarity scores: [[0.6473319  0.6468511  0.64471555]]\n"
     ]
    }
   ],
   "source": [
    "# New input product description\n",
    "input_text = [\"laptop charger\"]\n",
    "input_embedding = get_embeddings(input_text, model, tokenizer)\n",
    "\n",
    "# Normalize input embedding before searching\n",
    "input_embedding_f32 = np.ascontiguousarray(input_embedding.astype(np.float32))\n",
    "input_embedding_f32 = F.normalize(torch.tensor(input_embedding_f32), p=2, dim=1).numpy()\n",
    "\n",
    "# Define a similarity threshold (adjust based on your data)\n",
    "SIMILARITY_THRESHOLD = 0.38  # Lower scores mean low similarity\n",
    "\n",
    "# Perform the search\n",
    "D, I = index.search(input_embedding_f32, k=5)  # Get top 5 matches\n",
    "\n",
    "# Check if the best match is above the threshold\n",
    "if D[0][0] < SIMILARITY_THRESHOLD:\n",
    "    print(\"No relevant match found.\")\n",
    "    print(\"Similarity scores:\", D)\n",
    "else:\n",
    "    print(\"Most similar product indices:\", I)\n",
    "    print(\"Similarity scores:\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54032585-b94c-4992-a3d8-3fc00cbc79cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using nvcr.io/nvidia/tritonserver:24.01-py3 (a previous version of triton which has onnxruntime backend installed (cuDNN upgrade issue in the newer one))\n",
    "\n",
    "# Convert model to tensorrt (comes installed with the image)\n",
    "# /usr/src/tensorrt/bin/trtexec --onnx=model.onnx --saveEngine=model.trt --fp16\n",
    "\n",
    "# Start Triton\n",
    "# My folder is network stored, so all packages should be accesible\n",
    "\n",
    "# /opt/tritonserver/bin/tritonserver --model-repository=/workspace/model_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch is installed. Version: 2.6.0+cu126\n",
      "transformers is installed. Version: 4.49.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Function to check module installation and version\n",
    "def check_module(module_name):\n",
    "    module = importlib.util.find_spec(module_name)\n",
    "    if module:\n",
    "        imported_module = importlib.import_module(module_name)\n",
    "        version = getattr(imported_module, '__version__', 'Version not found')\n",
    "        print(f\"{module_name} is installed. Version: {version}\")\n",
    "    else:\n",
    "        print(f\"{module_name} is NOT installed.\")\n",
    "\n",
    "# Check torch and transformers\n",
    "check_module(\"torch\")\n",
    "check_module(\"transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.34092474 -0.7468907  -0.06713652 ...  0.06433069 -0.00998584\n",
      "  0.11809338]\n"
     ]
    }
   ],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer and Triton client\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"WhereIsAI/UAE-Large-V1\")\n",
    "client = httpclient.InferenceServerClient(url=\"localhost:8000\")\n",
    "\n",
    "MODEL_NAME=\"UAE-Large-V1\"\n",
    "\n",
    "# Example input text\n",
    "text = \"a black thing\"\n",
    "inputs = tokenizer(text, return_tensors=\"np\")\n",
    "\n",
    "# Triton requires token_type_ids along with input_ids and attention_mask\n",
    "input_ids = httpclient.InferInput(\"input_ids\", inputs[\"input_ids\"].shape, \"INT64\")\n",
    "attention_mask = httpclient.InferInput(\"attention_mask\", inputs[\"attention_mask\"].shape, \"INT64\")\n",
    "\n",
    "# Ensure token_type_ids exist (some models use it, some don't)\n",
    "if \"token_type_ids\" not in inputs:\n",
    "    inputs[\"token_type_ids\"] = np.zeros_like(inputs[\"input_ids\"])\n",
    "\n",
    "token_type_ids = httpclient.InferInput(\"token_type_ids\", inputs[\"token_type_ids\"].shape, \"INT64\")\n",
    "\n",
    "# Set data for inputs\n",
    "input_ids.set_data_from_numpy(inputs[\"input_ids\"])\n",
    "attention_mask.set_data_from_numpy(inputs[\"attention_mask\"])\n",
    "token_type_ids.set_data_from_numpy(inputs[\"token_type_ids\"])\n",
    "\n",
    "# Define the output tensor\n",
    "outputs = httpclient.InferRequestedOutput(\"last_hidden_state\")\n",
    "\n",
    "# Send inference request\n",
    "response = client.infer(model_name=MODEL_NAME, inputs=[input_ids, attention_mask, token_type_ids], outputs=[outputs])\n",
    "\n",
    "# Print response\n",
    "print(response.as_numpy(\"last_hidden_state\")[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9564e-02,  1.4224e-02, -4.2698e-02,  1.7461e-02, -5.0548e-03,\n",
       "         -1.6759e-02, -1.1440e-02, -2.8139e-02,  2.2130e-03, -5.4862e-02,\n",
       "         -5.1926e-02, -1.5328e-02, -3.9420e-02, -5.9082e-02, -4.1330e-02,\n",
       "         -5.6235e-03, -3.6205e-02,  2.5260e-02, -1.5978e-02, -7.5782e-02,\n",
       "         -3.2285e-02, -4.3216e-02, -8.1534e-03,  1.3770e-03, -5.7407e-02,\n",
       "         -3.4286e-02, -2.8380e-03, -1.3348e-02,  2.7440e-02, -1.5356e-02,\n",
       "         -8.4235e-03, -3.0112e-02, -4.9091e-02, -1.0906e-02, -3.4976e-02,\n",
       "         -3.2410e-02, -2.8491e-02, -5.8483e-02,  1.9913e-02, -3.7894e-02,\n",
       "         -5.7533e-03, -1.3862e-02, -2.3517e-02, -2.1590e-02,  1.9630e-02,\n",
       "         -2.6699e-02,  9.3951e-03, -2.5720e-02, -1.4409e-02, -1.1951e-02,\n",
       "         -1.3215e-02, -6.8224e-02,  1.4171e-02, -2.6513e-02, -7.3316e-02,\n",
       "         -2.8856e-02, -2.4893e-02, -5.4165e-02, -3.4994e-02, -3.1273e-02,\n",
       "          5.0158e-03, -6.3911e-03, -4.3383e-02, -1.1057e-02, -1.6693e-02,\n",
       "         -3.5838e-02,  1.5773e-02,  5.7383e-02, -2.8622e-02, -2.8718e-02,\n",
       "         -1.7301e-02, -3.1728e-02, -1.5474e-02, -4.2200e-02, -3.1879e-02,\n",
       "         -1.7907e-03, -8.7252e-02,  2.2071e-03, -5.3359e-02, -1.2663e-02,\n",
       "         -4.8347e-02,  1.4929e-02, -2.2791e-02, -3.0531e-02, -1.4018e-02,\n",
       "          3.8117e-03, -3.7223e-02, -4.6379e-02,  1.5267e-02, -9.9599e-03,\n",
       "         -6.5020e-02, -6.6597e-03, -3.8723e-02, -1.7264e-02,  1.6538e-03,\n",
       "         -4.2300e-02, -4.3436e-02, -3.5079e-02, -3.6888e-02, -5.5888e-02,\n",
       "         -3.1647e-02, -1.5751e-02, -1.3731e-02, -1.2310e-02, -4.8920e-02,\n",
       "         -1.0051e-02,  1.7031e-04, -3.5342e-02,  1.4636e-03, -5.8966e-02,\n",
       "         -7.6180e-03, -4.1349e-02, -2.4098e-02, -5.3127e-02,  6.3509e-03,\n",
       "         -3.8014e-02,  1.2327e-02, -1.7638e-02, -2.3598e-02, -2.7317e-02,\n",
       "         -3.5355e-02, -2.7507e-02, -8.1628e-02, -5.7700e-02, -9.7373e-03,\n",
       "         -6.7078e-02, -9.5642e-03, -8.7924e-02, -3.5687e-02,  5.9613e-02,\n",
       "         -3.1951e-02, -3.1226e-02, -2.4814e-02, -5.1796e-03, -2.5824e-02,\n",
       "         -2.8756e-02, -1.0928e-02, -4.9769e-02,  4.4014e-03, -4.8557e-02,\n",
       "         -5.2210e-02, -1.5369e-02,  1.4719e-03, -6.0788e-02,  1.1596e-03,\n",
       "         -2.1977e-02, -4.0025e-02, -2.0233e-02, -1.0062e-04, -1.1690e-02,\n",
       "         -2.9881e-02, -3.7951e-02, -3.7386e-02, -1.1753e-02, -6.9483e-02,\n",
       "          1.7468e-02, -4.3238e-03, -1.4461e-02, -1.5496e-02, -3.3421e-02,\n",
       "         -2.8526e-02, -1.5278e-02, -1.7183e-02,  5.9875e-03,  7.3464e-03,\n",
       "         -1.4056e-02,  1.5477e-02, -2.4572e-02, -2.9362e-02, -5.4656e-02,\n",
       "         -4.3205e-02,  8.9603e-04, -5.6649e-02, -3.9664e-02, -1.9852e-02,\n",
       "         -6.0649e-02, -9.0676e-02, -3.4307e-03,  2.3210e-02, -2.3738e-02,\n",
       "         -4.0158e-02, -1.9565e-03,  2.5188e-02, -4.4303e-02, -2.9505e-02,\n",
       "         -9.8843e-03, -3.8117e-03, -9.8593e-03, -5.3083e-03, -1.7834e-02,\n",
       "          1.5713e-02, -4.6403e-02, -4.0142e-02, -3.5378e-03, -2.9635e-02,\n",
       "          2.0068e-02, -3.8577e-02, -2.7877e-02, -2.4789e-02, -3.0738e-02,\n",
       "         -6.8558e-04,  4.3035e-02, -2.3279e-02, -3.5346e-02, -3.2254e-02,\n",
       "         -1.1714e-02, -5.8421e-02, -1.9524e-02, -3.3910e-02, -3.2922e-02,\n",
       "         -1.3784e-02,  4.2902e-04,  1.8014e-02, -1.4021e-02, -1.3352e-02,\n",
       "         -1.9270e-02, -4.0836e-02,  1.2964e-03, -3.6121e-02, -4.1623e-02,\n",
       "         -2.4431e-02, -5.0595e-02, -2.1798e-02,  1.2676e-02, -6.6549e-02,\n",
       "          1.0370e-02, -1.9989e-02, -4.6966e-03, -4.2082e-02, -2.9631e-02,\n",
       "          2.2125e-02, -2.9648e-02,  3.0226e-03, -1.0611e-02, -4.9028e-02,\n",
       "         -1.4002e-02, -5.9206e-02, -4.3115e-02, -1.2652e-02, -4.9049e-02,\n",
       "          8.9825e-03, -4.0952e-02,  3.8712e-02,  1.6735e-02, -5.2966e-02,\n",
       "         -3.4084e-02, -4.0567e-02, -5.5916e-02, -3.5287e-03, -4.1763e-02,\n",
       "         -3.2696e-02, -9.0009e-02, -5.6510e-02, -3.8552e-02, -1.0876e-02,\n",
       "         -2.3986e-02, -9.2834e-02, -3.3422e-02, -2.1338e-02, -2.0881e-02,\n",
       "         -1.5286e-02, -3.3780e-02, -2.3269e-02, -4.2145e-02, -3.2509e-02,\n",
       "         -1.8379e-02, -8.4313e-02, -6.6929e-02, -3.2608e-02, -8.3869e-02,\n",
       "         -4.5353e-02,  1.1855e-02,  6.5834e-03, -5.1900e-02, -3.1794e-02,\n",
       "         -1.6675e-02, -2.7063e-04, -3.6496e-02, -6.2621e-02, -2.0872e-02,\n",
       "         -1.3759e-02, -3.6318e-02, -4.7131e-02,  3.0639e-03, -2.9046e-02,\n",
       "         -3.6806e-02, -3.6445e-02, -6.3130e-03, -2.5984e-02, -1.5587e-02,\n",
       "         -3.0437e-02, -3.6576e-02, -8.9080e-04, -5.1746e-02, -5.1501e-02,\n",
       "         -8.1236e-02, -2.7158e-03, -5.8100e-02, -4.6365e-02, -3.1762e-02,\n",
       "         -2.6577e-02, -3.1856e-02, -2.9314e-02, -1.5134e-02, -3.4899e-02,\n",
       "         -6.1011e-02, -8.3759e-02, -3.2968e-02, -8.3443e-03,  9.5279e-03,\n",
       "         -4.3218e-02, -3.6389e-02, -2.7566e-02,  1.1529e-02, -2.4999e-02,\n",
       "         -4.4105e-03, -1.9369e-02, -5.6509e-02, -5.9023e-02, -7.9820e-02,\n",
       "         -2.1379e-02, -1.7162e-03, -2.7641e-02, -4.6291e-02,  2.4125e-02,\n",
       "         -2.0935e-02, -2.5785e-02, -1.0140e-02,  6.5609e-03, -3.1423e-02,\n",
       "         -3.2931e-02, -6.1628e-02, -2.4313e-02,  1.6855e-03,  2.7263e-02,\n",
       "         -1.0069e-02, -6.3256e-02, -1.7647e-02, -2.7360e-03, -7.5763e-03,\n",
       "         -6.9923e-03, -5.2903e-02, -8.4965e-03, -4.8465e-02,  1.1752e-02,\n",
       "         -1.7834e-02,  1.2341e-03, -1.0073e-02, -3.6586e-02,  9.0959e-03,\n",
       "          2.1382e-03,  4.1993e-02, -6.8343e-03,  2.0329e-03, -2.4301e-02,\n",
       "         -6.3279e-02, -1.4876e-02, -1.1825e-02, -5.5450e-02, -2.6398e-02,\n",
       "          5.8041e-03, -5.3552e-03,  7.2674e-02, -1.2418e-02, -1.8237e-02,\n",
       "         -1.0696e-02, -6.3884e-02, -5.6758e-03, -2.5041e-02, -1.8137e-02,\n",
       "         -1.3504e-02, -1.9496e-02, -4.5831e-02, -3.5735e-02, -2.2831e-02,\n",
       "          1.4250e-02, -4.2077e-02, -2.1699e-02, -7.0424e-03, -1.0697e-02,\n",
       "          1.6735e-02, -2.2702e-02, -3.6378e-02, -2.1220e-02, -2.8149e-02,\n",
       "         -2.5431e-02, -3.1614e-03, -3.0503e-02, -5.1723e-02, -5.4957e-02,\n",
       "         -8.5682e-02, -4.2265e-02, -6.1971e-03, -2.3245e-02, -3.6794e-02,\n",
       "          1.2398e-02,  1.1140e-02, -3.9856e-02, -4.1754e-02, -1.3093e-02,\n",
       "         -6.3238e-02, -1.8937e-02, -1.5095e-03,  1.3162e-02, -1.5930e-03,\n",
       "         -3.6532e-03, -8.2475e-02, -3.6000e-02, -2.2838e-02, -1.5639e-02,\n",
       "         -3.1927e-02, -3.4441e-02, -3.3549e-02, -5.1673e-02, -2.8814e-03,\n",
       "         -3.8773e-02, -2.1487e-02, -3.5783e-02, -4.7174e-02, -8.6609e-02,\n",
       "         -6.8360e-02, -4.7803e-02, -4.2010e-02, -3.6940e-02, -2.4519e-02,\n",
       "         -3.4458e-02, -3.8614e-02, -8.8909e-03, -2.4210e-02,  7.6635e-03,\n",
       "         -5.4414e-02, -1.3866e-02, -1.3337e-02, -5.8187e-03, -6.3747e-02,\n",
       "         -2.2477e-02, -2.3296e-02, -1.5963e-02, -1.7012e-02, -5.5371e-02,\n",
       "         -6.1258e-02, -6.9584e-03, -2.1665e-02, -3.5848e-02, -4.3721e-02,\n",
       "          7.7025e-03, -2.0046e-02, -4.0380e-02, -6.4611e-02, -5.7225e-02,\n",
       "         -2.7539e-02, -5.3199e-02, -2.5445e-02,  3.5466e-03,  2.6494e-02,\n",
       "         -1.9659e-02,  2.8810e-02, -1.0574e-01, -3.8510e-02, -5.4552e-03,\n",
       "         -3.3118e-02, -3.0473e-02, -3.3003e-02, -1.3422e-02, -6.2682e-03,\n",
       "         -3.8066e-02, -5.1405e-02, -1.1110e-01, -8.5520e-02,  3.2753e-03,\n",
       "         -6.0944e-02, -2.9309e-02, -6.8885e-02,  5.7576e-03, -3.8028e-02,\n",
       "         -4.7176e-02,  9.1960e-04, -6.0063e-02, -7.6283e-02, -6.2738e-02,\n",
       "         -2.0962e-02, -3.5844e-02,  3.1475e-02, -3.6781e-02, -1.5520e-02,\n",
       "          2.8015e-02, -4.3795e-02, -3.2996e-02, -7.9231e-03, -4.6892e-02,\n",
       "         -1.3803e-02,  2.7507e-02, -4.9670e-02, -1.9755e-02, -1.4189e-02,\n",
       "         -1.8459e-02, -2.1058e-02,  9.8498e-03,  3.1391e-02,  1.5137e-02,\n",
       "         -7.2751e-02, -2.2579e-02, -3.7909e-02, -6.7548e-02, -2.6095e-02,\n",
       "         -3.1301e-02,  4.0895e-02, -3.8261e-02, -3.8752e-02,  2.4331e-02,\n",
       "         -5.9252e-02, -1.2582e-02, -4.3373e-02,  2.1196e-04, -1.1284e-02,\n",
       "         -4.8739e-02, -3.4749e-02, -5.2474e-02, -4.9591e-02, -5.9271e-02,\n",
       "         -1.5787e-02, -1.4939e-02, -4.0315e-02, -8.5472e-03, -3.4393e-02,\n",
       "         -6.5824e-02,  2.8372e-02, -2.2647e-02,  2.6849e-02, -3.1570e-02,\n",
       "         -1.2416e-02, -6.7689e-02,  7.2332e-03,  2.6011e-02, -4.7889e-02,\n",
       "         -2.9481e-02,  2.0482e-02,  1.7109e-03, -5.3312e-03, -7.1542e-02,\n",
       "         -1.1244e-01, -3.9996e-02, -3.6352e-02,  4.2074e-03, -8.6352e-04,\n",
       "         -5.9498e-02, -4.4674e-02, -4.1761e-02, -1.7708e-02, -3.7783e-02,\n",
       "          7.5187e-03, -7.3181e-03, -3.7220e-02,  5.9106e-03, -2.2119e-02,\n",
       "         -2.1516e-02,  4.1469e-02,  3.8669e-02, -2.8419e-02, -4.0295e-03,\n",
       "         -4.7265e-02, -3.6822e-03,  2.8262e-02, -5.0526e-02,  6.8453e-04,\n",
       "         -7.0431e-02,  7.0303e-04, -6.3050e-03, -7.8289e-02,  4.3298e-03,\n",
       "         -3.8571e-02, -4.8061e-02, -1.5567e-02,  4.0918e-02, -1.1935e-03,\n",
       "         -4.6164e-02, -1.7421e-02, -1.7906e-02,  2.1790e-03, -6.7247e-02,\n",
       "         -1.2830e-02, -3.7254e-02, -2.9361e-02, -4.3863e-02, -2.4450e-02,\n",
       "         -3.7360e-02, -3.5289e-03,  3.0697e-02,  5.7090e-03, -5.8929e-02,\n",
       "         -4.0551e-02, -2.4041e-02, -1.2951e-02, -6.9501e-02, -3.2994e-03,\n",
       "         -4.4853e-02,  6.4578e-03, -1.5893e-02, -9.0281e-03, -5.0540e-02,\n",
       "         -5.3880e-03,  3.5957e-02, -1.9877e-02, -5.3861e-02, -2.6685e-02,\n",
       "         -2.3215e-02, -3.8414e-02, -3.6731e-04, -4.0021e-02, -3.2425e-02,\n",
       "         -1.3677e-02, -1.5663e-02, -1.5837e-02, -4.6440e-02, -2.3781e-02,\n",
       "         -2.3528e-02, -2.8754e-02, -1.1220e-02, -9.5735e-02, -1.8370e-02,\n",
       "          3.5591e-02, -7.2553e-03, -1.2581e-02,  1.6072e-03, -1.1959e-02,\n",
       "         -1.1893e-02, -7.7988e-02, -6.2117e-02, -7.4215e-02, -4.4998e-03,\n",
       "          8.2951e-04, -1.5774e-02, -7.4447e-03, -1.9098e-02, -4.2370e-02,\n",
       "          5.1469e-02,  4.9203e-03, -4.1274e-02, -1.8897e-02,  7.0833e-03,\n",
       "          6.5565e-03, -1.8969e-03, -5.7713e-02, -3.1955e-02, -1.3984e-02,\n",
       "         -3.2039e-02, -1.2804e-02, -7.5746e-04, -2.7724e-02, -2.0467e-03,\n",
       "         -4.8296e-02, -2.1530e-02, -4.6715e-02, -7.0249e-02, -6.2636e-02,\n",
       "         -3.6825e-02, -4.5881e-02, -4.4646e-02, -2.9497e-02, -2.5938e-03,\n",
       "         -2.7842e-02, -5.3402e-02, -1.3068e-02, -1.6996e-02,  7.3596e-03,\n",
       "         -3.4792e-02, -2.0797e-02, -4.8935e-02,  1.4451e-02, -4.8508e-02,\n",
       "         -6.6863e-03, -1.4741e-02, -2.4678e-02, -5.7079e-02, -9.0466e-03,\n",
       "         -6.3712e-02, -2.3525e-02, -3.2012e-02, -5.0649e-02, -4.1717e-02,\n",
       "         -5.5945e-02, -4.0114e-02, -1.7319e-02, -4.5020e-02, -7.7508e-02,\n",
       "         -1.8565e-02, -1.6770e-02, -2.4702e-02, -2.3936e-02,  3.7739e-03,\n",
       "          1.8868e-02,  9.6879e-03, -1.5354e-02, -5.3953e-02, -3.4084e-02,\n",
       "         -1.7541e-02, -1.4457e-02,  1.0563e-02, -4.7877e-02, -1.7210e-02,\n",
       "         -4.0890e-02, -3.1391e-02,  8.9434e-03, -7.2360e-02, -1.4077e-02,\n",
       "         -7.4466e-03, -1.9548e-02, -6.5751e-02, -4.5771e-02, -6.4822e-03,\n",
       "         -8.5615e-02, -1.9273e-02, -4.7238e-02,  2.3230e-02,  1.1321e-03,\n",
       "         -7.4983e-03, -2.4748e-02, -4.4429e-02, -1.9409e-03, -3.3474e-03,\n",
       "          2.4390e-02, -3.1398e-02,  1.0261e-02,  2.5266e-02, -2.8957e-02,\n",
       "         -3.4510e-02, -2.0530e-02, -2.5215e-02, -7.3231e-02, -6.3467e-04,\n",
       "         -8.7851e-03,  5.2258e-03, -5.5884e-04, -2.8066e-02, -4.1861e-03,\n",
       "          5.8832e-03, -3.6711e-02, -5.5620e-02, -5.4403e-02,  9.4826e-03,\n",
       "         -2.3237e-02, -3.3713e-02,  1.6582e-02, -4.7110e-02, -3.4102e-02,\n",
       "          1.7521e-02, -1.2310e-02, -2.0426e-02, -2.8268e-02, -1.9576e-02,\n",
       "         -3.5537e-02, -2.7565e-03, -5.3725e-02, -4.0746e-02, -1.8387e-02,\n",
       "         -3.1889e-03, -2.0905e-02, -1.4131e-02, -3.1154e-02,  3.5920e-03,\n",
       "         -4.4359e-02, -7.4113e-02, -2.6110e-02, -4.5918e-02, -2.6354e-02,\n",
       "         -3.2321e-02, -7.0159e-03, -3.6354e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Triton server details\n",
    "TRITON_SERVER_URL = \"localhost:8000\"\n",
    "MODEL_NAME = \"nomic-embed-vision\"\n",
    "\n",
    "# Load the image processor (same as used in ONNX model)\n",
    "processor = AutoImageProcessor.from_pretrained(\"/workspace/onnx-nomic-embed-v1.5\")\n",
    "\n",
    "# Load an image\n",
    "image_url = \"https://m.media-amazon.com/images/I/61sADwl+YWL._AC_UL320_.jpg\"  # Replace with your own image\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "# Preprocess image\n",
    "inputs = processor(image, return_tensors=\"np\")\n",
    "input_data = inputs[\"pixel_values\"]  # Shape should be (1, 3, 224, 224)\n",
    "\n",
    "# Initialize Triton client\n",
    "client = httpclient.InferenceServerClient(url=TRITON_SERVER_URL)\n",
    "\n",
    "# Prepare request\n",
    "input_tensor = httpclient.InferInput(\"pixel_values\", input_data.shape, \"FP32\")\n",
    "input_tensor.set_data_from_numpy(input_data, binary_data=True)\n",
    "\n",
    "# Request both outputs\n",
    "output_tensor = httpclient.InferRequestedOutput(\"last_hidden_state\", binary_data=True)\n",
    "\n",
    "# Run inference\n",
    "response = client.infer(model_name=MODEL_NAME, inputs=[input_tensor], outputs=[output_tensor])\n",
    "\n",
    "# Extract embeddings\n",
    "output = response.as_numpy(\"last_hidden_state\")  # Shape: (1, 197, 768)\n",
    "\n",
    "# Normalize embeddings (Optional: Usually done to get unit vectors)\n",
    "img_embeddings = torch.tensor(output)\n",
    "normalized_embeddings = F.normalize(img_embeddings[:, 0], p=2, dim=1)\n",
    "\n",
    "# Print the shape and embeddings\n",
    "# print(\"Image Embeddings Shape:\", normalized_embeddings.shape)\n",
    "normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
